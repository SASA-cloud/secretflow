{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325403a3-9be9-403f-a44f-36d20054789a",
   "metadata": {},
   "source": [
    "# SplitRec：在隐语拆分学习中使用 FeatureInferenceAttack\n",
    "在联邦学习中，攻击者可以通过监听训练模型过程中传输的数值和梯度信息，攻击对方模型或数据，在一定程度上推理出有用信息，造成信息泄露。\n",
    "\n",
    "本文考虑两方拆分学习中的特征推理攻击，将介绍[《Feature Inference Attacks on Model Predictions in Vertical Federated Learning》](https://arxiv.org/abs/2010.10152)中的 GRN 攻击方法在隐语中的使用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b04cd-77dc-4fa6-937d-4a1f3b9e1f16",
   "metadata": {},
   "source": [
    "## Feature Inference Attack with Generative Regression Network\n",
    "特征推理攻击中，有标签的一方作为攻击方，推测对方的特征。在联邦模型训练之后，GRN 攻击方法通过一个生成回归网络（Generator Model）预测对方特征，并通过不断缩小预测特征在联邦模型的输出值和真实联邦模型输出值的差距，训练 Genertor Model，因而可以预测对方特征，如下图所示。\n",
    "\n",
    "![fia0](resources/fia0.png)\n",
    "\n",
    "其中 Generator Model 具体训练步骤如下：\n",
    "\n",
    "1. 将攻击方特征（蓝色）和随机生成的数据（橙色）输入到 Generator Model 中，输出值作为预测的对方特征\n",
    "2. 将攻击方特征和预测的对方特征输入已经训完的联邦模型中，计算 logit 输出\n",
    "3. 利用步骤 2 中输出的 logit 与真实 logit（攻击方特征和对方真实特征输入联邦模型计算的 logit）计算损失\n",
    "4. 对得到的损失进行反向传播，更新 Generator Model 参数\n",
    "\n",
    "算法伪代码如下：\n",
    "\n",
    "![fia1](resources/fia1.png)\n",
    "\n",
    "loss 函数定义如下：\n",
    "\n",
    "![fia2](resources/fia2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883eac32-bce1-435e-9922-98fd944c4e4b",
   "metadata": {},
   "source": [
    "## 隐语中的攻击方法实现\n",
    "在隐语中攻击方法的实现是通过 callback 机制来完成。攻击算法基类 CallBack 位于 secretflow/ml/nn/sl/backend/torch/callback.py，我们在联邦模型训练的以下几个节点提供 hook，不同攻击方法可以通过将攻击算法实现在对应节点的 hook， 使攻击逻辑注入到联邦模型的训练过程中。\n",
    "\n",
    "- on_train_begin\n",
    "- on_train_end\n",
    "- on_epoch_begin\n",
    "- on_epoch_end\n",
    "- on_batch_begin\n",
    "- on_batch_end\n",
    "\n",
    "用户如果需要实现自定义的攻击方法，需要\n",
    "\n",
    "1. 定义 CustomAttacker 继承基类 Callback，将攻击逻辑实现到对应的 hook 函数中\n",
    "2. 定义 attacker_builder 函数将构建 attacker 写到其中\n",
    "3. 与普通 Split Learning 模型训练一样定义 sl_model, 并在调用 sl_model.fit() 时，将 callback_dict {party -> attacker_builder} 传入 callbacks 参数即可\n",
    "\n",
    "其中步骤 1 可以参考隐语中已有的 FeatureInferenceAttacker/LabelInferenceAttacker，步骤 2 和 3 可参考下面 FeatureInferenceAttacker 的使用方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9a8f4-7335-4380-a8ab-f10d93548382",
   "metadata": {},
   "source": [
    "## Feature Inferece Attack 的隐语封装\n",
    "我们在隐语中提供了多种攻击方法的封装。对于论文中的攻击方法，我们提供了 FeatureInferenceAttacker 封装，具体使用可以参考以下代码。\n",
    "\n",
    "首先和一般 Split Learning 模型训练一样，我们将进行数据处理，并定义一个 SLModel。\n",
    "\n",
    "然后定义调用 FeatureInferenceAttacker 的 attacker_builder，并在 SLModel fit 时将 attacker_builder 传入进行训练和攻击。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d8a72-1c4f-40b9-bbea-2e9c6ca8e86a",
   "metadata": {},
   "source": [
    "## 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adf7fd9-cf8c-4dad-913f-512d3bfedade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.7.0b0\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "# sf.init(['alice', 'bob'], address=\"local\")\n",
    "sf.init(['alice', 'bob'], address=\"local\", debug_mode=True)\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "device_y = alice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afcf4b7-c795-4c12-b725-7607f5b15018",
   "metadata": {},
   "source": [
    "## 数据集介绍\n",
    "这里我们使用 UCI Sensorless Drive Diagnosis 数据集，该数据集有 48 维特征 11 分类。\n",
    "\n",
    "这里我们对数据进行纵向切分，攻击方持有 28 维特征和 label，被攻击方持有 20 维特征。\n",
    "\n",
    "[数据集官网](http://archive.ics.uci.edu/dataset/325/dataset+for+sensorless+drive+diagnosis)\n",
    "\n",
    "这里可以下载论文代码数据集： [drive_cleaned.csv](https://raw.githubusercontent.com/xinjianluo/featureinference-vfl/master/datasets/drive_cleaned.csv)\n",
    "\n",
    "或直接使用我们提供的 demo 数据 drive_cleaned_demo.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5affd8-8fbc-4fdb-9d1c-ff73a0a18d82",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2468168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.data.core.agent.PartitionAgent'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.data.core.agent.PartitionAgent'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.data.core.agent.PartitionAgent'> with party alice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
      "data.dtypes:  {'age': dtype('float32'), 'job': dtype('float32'), 'marital': dtype('float32'), 'education': dtype('float32'), 'default': dtype('float32'), 'balance': dtype('float32'), 'housing': dtype('float32'), 'loan': dtype('float32'), 'contact': dtype('float32'), 'day': dtype('float32'), 'month': dtype('float32'), 'duration': dtype('float32'), 'campaign': dtype('float32'), 'pdays': dtype('float32'), 'previous': dtype('float32'), 'poutcome': dtype('float32')}\n",
      "label.dtypes:  {'y': dtype('float32')}\n",
      "3616\n",
      "type(bob_mean):  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengruijun/miniconda3/envs/drj-sf/lib/python3.10/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/dengruijun/miniconda3/envs/drj-sf/lib/python3.10/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 分割alice和bob的数据集的schema（不是数据集本身）\n",
    "\n",
    "from secretflow.utils.simulation.datasets import load_bank_marketing\n",
    "\n",
    "# Alice has the first four features,\n",
    "# while bob has the left features\n",
    "data = load_bank_marketing(parts={alice: (0, 4), bob: (4, 16)}, axis=1)\n",
    "# Alice holds the label.\n",
    "label = load_bank_marketing(parts={alice: (16, 17)}, axis=1)\n",
    "\n",
    "from secretflow.preprocessing.scaler import MinMaxScaler\n",
    "from secretflow.preprocessing.encoder import LabelEncoder\n",
    "\n",
    "# 类别类编码\n",
    "encoder = LabelEncoder()\n",
    "data['job'] = encoder.fit_transform(data['job'])\n",
    "data['marital'] = encoder.fit_transform(data['marital'])\n",
    "data['education'] = encoder.fit_transform(data['education'])\n",
    "data['default'] = encoder.fit_transform(data['default'])\n",
    "data['housing'] = encoder.fit_transform(data['housing'])\n",
    "data['loan'] = encoder.fit_transform(data['loan'])\n",
    "data['contact'] = encoder.fit_transform(data['contact'])\n",
    "data['poutcome'] = encoder.fit_transform(data['poutcome'])\n",
    "data['month'] = encoder.fit_transform(data['month'])\n",
    "label = encoder.fit_transform(label)\n",
    "\n",
    "# 归一化、 打印数据信息 \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "# data.astype('float32')\n",
    "# print('type(data)=', type(data))\n",
    "print(data.columns)\n",
    "# print(data['job'].loc[0:0])\n",
    "\n",
    "# print(data[alice].shape)\n",
    "# print(data)\n",
    "# print(data.partitions)\n",
    "# print(data.columns) # alice和bob的数据集的列名（总的列表）\n",
    "# print(data.partition_columns) # alice和bob的数据集的列名（分别）\n",
    "# print(\"data.dtypes: \",data.dtypes)\n",
    "# print('label.dtypes: ', label.dtypes)\n",
    "\n",
    "# 转换dtypes\n",
    "# float64 to float32\n",
    "float64_colomns = data.select_dtypes(include=['float64']).columns\n",
    "print(float64_colomns)\n",
    "data[float64_colomns] = data[float64_colomns].astype('float32')\n",
    "\n",
    "label=label.astype('float32')\n",
    "\n",
    "print(\"data.dtypes: \",data.dtypes)\n",
    "print(\"label.dtypes: \",label.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "# 切分数据集（训练&测试）\n",
    "from secretflow.data.split import train_test_split\n",
    "\n",
    "random_state = 1234\n",
    "train_fea, test_fea, = train_test_split(\n",
    "    data, train_size=0.8, random_state=random_state\n",
    ")\n",
    "train_label, test_label = train_test_split(\n",
    "    label, train_size=0.8, random_state=random_state\n",
    ")\n",
    "\n",
    "print(train_fea.values.partition_shape()[alice][0],) # 总的样本数目\n",
    "\n",
    "# 获取 data feature mean\n",
    "mean_attr = data.mean() # 样本均值\n",
    "# bob_mean = sf.reveal(mean_attr.partitions[bob].data).values\n",
    "bob_mean = mean_attr[4:].values\n",
    "print('type(bob_mean): ', type(bob_mean))\n",
    "# print('bob_mean: ', bob_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffa6eb0-a40a-4424-b59a-968711fa79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from secretflow.data.ndarray import FedNdarray, PartitionWay\n",
    "# from secretflow.utils.simulation.datasets import _DATASETS, get_dataset\n",
    "\n",
    "\n",
    "# def prepare_data():\n",
    "#     data_path = get_dataset(_DATASETS['drive_cleaned'])\n",
    "#     full_data_table = np.genfromtxt(data_path, delimiter=',')\n",
    "#     samples = full_data_table[:, :-1].astype(np.float32)\n",
    "#     labels = full_data_table[:, -1].astype(np.int64)\n",
    "\n",
    "#     # permuate columns\n",
    "#     batch, columns = samples.shape\n",
    "#     permu_cols = np.random.permutation(columns)\n",
    "#     samples = samples[:, permu_cols]\n",
    "\n",
    "#     # normalize feature\n",
    "#     fea_min = samples.min(axis=0)\n",
    "#     fea_max = samples.max(axis=0)\n",
    "#     samples = (samples - fea_min) / (fea_max - fea_min)\n",
    "#     mean_attr = samples.mean(axis=0) # 样本均值\n",
    "\n",
    "#     # split train, test, pred\n",
    "#     random_selection = np.random.rand(samples.shape[0]) <= 0.6\n",
    "#     train_sample = samples[random_selection]\n",
    "#     train_label = labels[random_selection]\n",
    "#     sample_left = samples[~random_selection]\n",
    "#     label_left = labels[~random_selection]\n",
    "\n",
    "#     random_selection = np.random.rand(sample_left.shape[0]) <= 0.5\n",
    "#     test_sample = sample_left[random_selection]\n",
    "#     test_label = label_left[random_selection]\n",
    "#     pred_sample = sample_left[~random_selection]\n",
    "#     pred_label = label_left[~random_selection]\n",
    "\n",
    "#     return (\n",
    "#         train_sample,\n",
    "#         train_label,\n",
    "#         test_sample,\n",
    "#         test_label,\n",
    "#         pred_sample,\n",
    "#         pred_label,\n",
    "#         mean_attr,\n",
    "#     )\n",
    "\n",
    "# # 获取数据集\n",
    "# (\n",
    "#     train_fea,\n",
    "#     train_label,\n",
    "#     test_fea,\n",
    "#     test_label,\n",
    "#     pred_fea,\n",
    "#     pred_label,\n",
    "#     mean_attr,\n",
    "# ) = prepare_data()\n",
    "\n",
    "# # bob 样本均值 bob是被攻击者\n",
    "# bob_mean = mean_attr[28:]\n",
    "\n",
    "# # train and test feature\n",
    "# fed_data = FedNdarray(\n",
    "#     partitions={\n",
    "#         alice: alice(lambda x: x[:, :28])(train_fea),\n",
    "#         bob: bob(lambda x: x[:, 28:])(train_fea),\n",
    "#     },\n",
    "#     partition_way=PartitionWay.VERTICAL,\n",
    "# )\n",
    "# test_fed_data = FedNdarray(\n",
    "#     partitions={\n",
    "#         alice: alice(lambda x: x[:, :28])(test_fea),\n",
    "#         bob: bob(lambda x: x[:, 28:])(test_fea),\n",
    "#     },\n",
    "#     partition_way=PartitionWay.VERTICAL,\n",
    "# )\n",
    "\n",
    "# # train and test label\n",
    "# test_data_label = device_y(lambda x: x)(test_label)\n",
    "# label = device_y(lambda x: x)(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d946f8-0038-4c59-b804-a119a016fc2a",
   "metadata": {},
   "source": [
    "## 定义 SL 模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf15a00-2622-4d2b-865f-c5bbedf08797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from secretflow.ml.nn.core.torch import BaseModule\n",
    "\n",
    "\n",
    "class SLBaseNet(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, output_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.output_num_value = output_dim\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "    def output_num(self): # 学习 secretflow/ml/nn/applications/sl_dnn_torch.py\n",
    "        return 1\n",
    "\n",
    "class SLFuseModel(BaseModule):\n",
    "    def __init__(self,input_dim, output_dim, party_num):\n",
    "        super().__init__()\n",
    "\n",
    "        # layers = []\n",
    "        # for i in range(party_num):\n",
    "            # layers.append(nn.Linear(input_dim, output_dim))\n",
    "        nn_layers = []\n",
    "        self.total_input_dim = input_dim * party_num\n",
    "        self.fc1 = nn.Linear(self.total_input_dim, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.cat(x,dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ac046-96a7-4aa4-9a01-46394e30b1fc",
   "metadata": {},
   "source": [
    "## 定义 SL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d7ca2d-c10d-4ccb-8340-ba9fb799cafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "# torch相关\n",
    "from secretflow.ml.nn.core.torch import (\n",
    "    metric_wrapper,\n",
    "    optim_wrapper,\n",
    "    BaseModule,\n",
    "    TorchModel,\n",
    ")\n",
    "from torchmetrics import Accuracy, Precision\n",
    "from secretflow.security.aggregation import SecureAggregator\n",
    "from secretflow.utils.simulation.datasets import load_mnist\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "from secretflow.ml.nn import SLModel\n",
    "\n",
    "hidden_size = 64\n",
    "\n",
    "def model_base_alice_fn():\n",
    "    def create_model():\n",
    "        return SLBaseNet(input_dim=4, output_dim=hidden_size)\n",
    "    return create_model\n",
    "\n",
    "def model_base_bob_fn():\n",
    "    def create_model():\n",
    "        return SLBaseNet(input_dim=12, output_dim=hidden_size)\n",
    "    return create_model\n",
    "\n",
    "model_base_alice = TorchModel(\n",
    "    model_fn=model_base_alice_fn(),\n",
    "    loss_fn=nn.BCELoss,\n",
    "    optim_fn = optim_wrapper(optim.Adam),\n",
    "    metrics = [\n",
    "    metric_wrapper(Accuracy, task='binary',),\n",
    "    metric_wrapper(Precision, task='binary',),\n",
    "    ],\n",
    "    # input_dim=4, output_dim=hidden_size,\n",
    "    )\n",
    "\n",
    "model_base_bob = TorchModel(\n",
    "    model_fn=model_base_bob_fn(),\n",
    "    loss_fn=nn.BCELoss,\n",
    "    optim_fn = optim_wrapper(optim.Adam),\n",
    "    metrics = [\n",
    "    metric_wrapper(Accuracy, task='binary',),\n",
    "    metric_wrapper(Precision, task='binary',),\n",
    "    ],\n",
    "    # input_dim=12, output_dim=hidden_size,\n",
    "    )\n",
    "\n",
    "def model_fuse_fn():\n",
    "    def create_model():\n",
    "        return SLFuseModel(input_dim=64, output_dim=1, party_num=2)\n",
    "    return create_model\n",
    "\n",
    "fuse_model = TorchModel(\n",
    "    model_fn=model_fuse_fn(),\n",
    "    loss_fn=nn.BCELoss,\n",
    "    optim_fn = optim_wrapper(optim.Adam),\n",
    "    metrics = [\n",
    "    metric_wrapper(Accuracy, task='binary',),\n",
    "    metric_wrapper(Precision, task='binary',),\n",
    "    ],\n",
    "    # input_dim=64, output_dim=1, party_num=2,\n",
    "    )\n",
    "\n",
    "\n",
    "base_model_dict = {alice: model_base_alice, bob: model_base_bob}\n",
    "\n",
    "sl_model = SLModel(\n",
    "    base_model_dict=base_model_dict,\n",
    "    device_y=device_y,\n",
    "    model_fuse=fuse_model,\n",
    "    dp_strategy_dict=None,\n",
    "    compressor=None,\n",
    "    simulation=True,\n",
    "    random_seed=1234,\n",
    "    backend='torch',\n",
    "    strategy='split_nn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182424d-1ac6-4674-94ba-e0d20a8d670f",
   "metadata": {},
   "source": [
    "## 定义 attacker_builder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec2b5d",
   "metadata": {},
   "source": [
    "### 1. FeatureInferenceAttacker\n",
    "#### 定义 FeatureInferenceAttacker 中的 Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1493b80c-4988-4828-b2c2-139cf49f6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从原始数据 生成 victim的feature\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=16, target_dim=12): # 生成的是被攻击者的数据\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 600),\n",
    "            nn.LayerNorm(600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 200),\n",
    "            nn.LayerNorm(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.LayerNorm(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, target_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2982182-1da0-4ee0-825e-9db1c7c2738e",
   "metadata": {},
   "source": [
    "#### 定义 FeatureInferenceAttacker 中的 data_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af36a38-c818-4c2d-be33-ff2d9686cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# 用于攻击的数据。\n",
    "def data_builder(data, label, batch_size):\n",
    "    def prepare_data():\n",
    "        # alice_data = data[:, :4]\n",
    "        # bob_data = data[:, 4:16]\n",
    "\n",
    "        numpy_alice = sf.reveal(data.partitions[alice].data).values\n",
    "        numpy_bob = sf.reveal(data.partitions[bob].data).values\n",
    "        alice_data = torch.tensor(numpy_alice, dtype=torch.float32)\n",
    "        bob_data = torch.tensor(numpy_bob, dtype=torch.float32)\n",
    "\n",
    "        alice_dataset = TensorDataset(torch.tensor(alice_data))\n",
    "        alice_dataloader = DataLoader(\n",
    "            dataset=alice_dataset,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        bob_dataset = TensorDataset(torch.tensor(bob_data))\n",
    "        bob_dataloader = DataLoader(\n",
    "            dataset=bob_dataset,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        dataloader_dict = {'alice': alice_dataloader, 'bob': bob_dataloader}\n",
    "        return dataloader_dict, dataloader_dict # 返回的是两个一样的，因为攻击者和被攻击者的数据是一样的emm\n",
    "\n",
    "    return prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed700079-748b-418a-a894-e599de0c3f44",
   "metadata": {},
   "source": [
    "#### 定义 attacker_builder\n",
    "这里 attacker_builder 是一个字典，其元素是参与方和对应的 attacker_builder_function，通常只需要填充攻击方和对应的 attacker_builder_function。\n",
    "\n",
    "由于本文中的特征攻击算法需要对方 base 模型参数，这里我们通过被攻击方在训练结束时将 base 模型保存到磁盘，攻击方从磁盘对应路径加载模型得到对应 base 模型来实现，因而这里双方都有对应的 attacker_builder。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a18d6ae-2fa7-415e-b090-427d3f741333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从这里导出攻击方法类\n",
    "\n",
    "from secretflow.ml.nn.sl.attacks.fia_torch import (\n",
    "    FeatureInferenceAttack,\n",
    "    # SaveModelCallback,\n",
    ")\n",
    "\n",
    "# FIA\n",
    "def create_attacker_builder(\n",
    "    model_save_path, bob_mean, pred_data, pred_label, batch_size, save_model_path\n",
    "):\n",
    "    def attacker_builder():\n",
    "        victim_model_dict = {\n",
    "            'bob': [SLBaseNet, model_save_path], # bob输入的是10啊？\n",
    "        }\n",
    "        optim_fn = optim_wrapper(optim.Adam, lr=0.0001)\n",
    "        generator_model = TorchModel(\n",
    "            model_fn=Generator,\n",
    "            loss_fn=None,\n",
    "            optim_fn=optim_fn,\n",
    "            metrics=None,\n",
    "        )\n",
    "\n",
    "        data_buil = data_builder(pred_data, pred_label, batch_size)\n",
    "\n",
    "        attacker = FeatureInferenceAttack(\n",
    "            victim_model_dict=victim_model_dict,\n",
    "            attack_party = alice,\n",
    "            victim_party = bob,\n",
    "            base_model_list=[alice,bob],\n",
    "            generator_model_wrapper=generator_model,\n",
    "            data_builder=data_buil,\n",
    "            victim_fea_dim=[12],\n",
    "            attacker_fea_dim=[4],\n",
    "            enable_mean=True,\n",
    "            enable_var=True,\n",
    "            victim_mean_feature=bob_mean,\n",
    "            save_attacker_path=save_model_path,\n",
    "            load_attacker_path = None,\n",
    "        )\n",
    "        return attacker\n",
    "\n",
    "    return attacker_builder\n",
    "\n",
    "\n",
    "# in Algorithm 2 line 9, attacker will inference v_hat so attacker should get the whole federated model(which maybe unrealistic)\n",
    "# victim bob will call this callback_builder to save base model first, then attacker alice loads this victim's model from the same path\n",
    "# def create_victim_callback_builder(model_save_path):\n",
    "#     def builder():\n",
    "#         cb = SaveModelCallback(model_save_path)\n",
    "#         return cb\n",
    "\n",
    "#     return builder\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "fia_path = '/home/dengruijun/data/FinTech/Products/secretflow/drj-outs/FIA/models/'\n",
    "if os.path.exists(fia_path):\n",
    "    shutil.rmtree(fia_path)\n",
    "os.mkdir(fia_path)\n",
    "model_save_path = fia_path + '/sl_model_victim'\n",
    "generator_save_path = fia_path + '/generator'\n",
    "fuse_model_save_path = fia_path+'/sl_model_fuse'\n",
    "\n",
    "# callback_dict = {\n",
    "#     alice: create_attacker_builder(\n",
    "#         model_save_path,\n",
    "#         bob_mean,\n",
    "#         pred_fea,\n",
    "#         pred_label,\n",
    "#         batch_size,\n",
    "#         generator_save_path,\n",
    "#     ),\n",
    "#     bob: create_victim_callback_builder(model_save_path),\n",
    "# }\n",
    "\n",
    "callback_dict = [create_attacker_builder(\n",
    "        model_save_path,\n",
    "        bob_mean,\n",
    "        test_fea,\n",
    "        test_label,\n",
    "        batch_size,\n",
    "        generator_save_path,\n",
    "    )()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec1463",
   "metadata": {},
   "source": [
    "### 2.Model Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e65fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02030f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c2409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871655bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e1110d7-6f66-4b5b-8f3d-95088fcef5c4",
   "metadata": {},
   "source": [
    "## 开始训练和攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80f51bb-70d3-46c2-a5cc-f3fe45777b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:SL Train Params: {'self': <secretflow.ml.nn.sl.sl_model.SLModel object at 0x7fbadbf8bf70>, 'x': VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7fbb89774c40>, PYURuntime(bob): <secretflow.data.core.partition.Partition object at 0x7fbb897750f0>}, aligned=True), 'y': VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7fbb897759f0>}, aligned=True), 'batch_size': 64, 'epochs': 1, 'verbose': 1, 'callbacks': [<secretflow.ml.nn.sl.attacks.fia_torch.FeatureInferenceAttack object at 0x7fbadb2cf820>], 'validation_data': (VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7fbb89774e80>, PYURuntime(bob): <secretflow.data.core.partition.Partition object at 0x7fbb89775300>}, aligned=True), VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7fbb89775d20>}, aligned=True)), 'shuffle': False, 'sample_weight': None, 'validation_freq': 1, 'dp_spent_step_freq': None, 'dataset_builder': None, 'audit_log_params': {}, 'early_stopping_batch_step': 0, 'early_stopping_warmup_step': 0, 'random_seed': 1234, 'audit_log_dir': None}\n",
      " 98%|█████████▊| 56/57 [00:00<00:00, 100.93it/s, {'train_loss': array(0.36142364, dtype=float32), 'train_BinaryAccuracy': array(0.8420907, dtype=float32), 'train_BinaryPrecision': array(0.08955224, dtype=float32), 'val_loss': array(0.17533527, dtype=float32), 'val_BinaryAccuracy': array(0.8729282, dtype=float32), 'val_BinaryPrecision': array(0., dtype=float32)}]\n",
      "/tmp/ipykernel_944917/2739045507.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  alice_dataset = TensorDataset(torch.tensor(alice_data))\n",
      "/tmp/ipykernel_944917/2739045507.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bob_dataset = TensorDataset(torch.tensor(bob_data))\n",
      "INFO:root:In epoch 0, loss is 1.121535062789917\n",
      "INFO:root:Mean generator loss: 0.118563112616539\n",
      "INFO:root:Mean random guess loss: 0.19375928243001303\n",
      "INFO:root:Mean generator loss Per Feature: [0.06449216 0.06409151 0.25452912 0.13940742 0.20837437 0.080477\n",
      " 0.08354268 0.16903134 0.08150743 0.08679091 0.05676358 0.13374984]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13123737 0.10000144 0.39364881 0.23293736 0.32365789 0.19260596\n",
      " 0.22534644 0.13310922 0.13154832 0.12391036 0.11587718 0.22123101]\n",
      "INFO:root:In epoch 1, loss is 0.5370686054229736\n",
      "INFO:root:Mean generator loss: 0.10222526341676712\n",
      "INFO:root:Mean random guess loss: 0.19157637556393942\n",
      "INFO:root:Mean generator loss Per Feature: [0.05484498 0.03429062 0.25120119 0.13670897 0.20863713 0.07746976\n",
      " 0.08396311 0.09158493 0.05171857 0.06248308 0.04675769 0.12704315]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14061501 0.13230345 0.3645336  0.24216047 0.32837499 0.1943433\n",
      " 0.19676311 0.11852831 0.10707008 0.11986384 0.12581345 0.22854688]\n",
      "INFO:root:In epoch 2, loss is 0.3840025067329407\n",
      "INFO:root:Mean generator loss: 0.09452661623557408\n",
      "INFO:root:Mean random guess loss: 0.19383102357387544\n",
      "INFO:root:Mean generator loss Per Feature: [0.04995146 0.02300737 0.24857098 0.13455647 0.20645052 0.0763861\n",
      " 0.08150975 0.06049623 0.0423888  0.05248674 0.03992084 0.11859414]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13540483 0.10716572 0.36935517 0.24952549 0.34140573 0.2022053\n",
      " 0.19944282 0.1112128  0.12722385 0.13678298 0.11156785 0.23467969]\n",
      "INFO:root:In epoch 3, loss is 0.29868265986442566\n",
      "INFO:root:Mean generator loss: 0.0894744023680687\n",
      "INFO:root:Mean random guess loss: 0.18978291749954224\n",
      "INFO:root:Mean generator loss Per Feature: [0.04080323 0.01768273 0.24930287 0.13391557 0.20538263 0.07557933\n",
      " 0.07725874 0.04652019 0.03650344 0.04788758 0.02798506 0.1148715 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13147693 0.11481948 0.37015863 0.24275622 0.32474486 0.21016257\n",
      " 0.20279189 0.12020526 0.1078664  0.11378389 0.12103449 0.21759446]\n",
      "INFO:root:In epoch 4, loss is 0.2390199452638626\n",
      "INFO:root:Mean generator loss: 0.08629374156395594\n",
      "INFO:root:Mean random guess loss: 0.19691783487796782\n",
      "INFO:root:Mean generator loss Per Feature: [0.03644795 0.01481919 0.24968688 0.13310579 0.20411174 0.07523366\n",
      " 0.07584615 0.03638409 0.03136258 0.0429901  0.02209396 0.11344281]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13875598 0.11116982 0.39071142 0.2464004  0.34752139 0.19153443\n",
      " 0.2089251  0.12159442 0.12259084 0.13216532 0.12477645 0.22686847]\n",
      "INFO:root:In epoch 5, loss is 0.20261074602603912\n",
      "INFO:root:Mean generator loss: 0.08428534617026646\n",
      "INFO:root:Mean random guess loss: 0.19285887281099956\n",
      "INFO:root:Mean generator loss Per Feature: [0.03413824 0.01306105 0.25012659 0.13128051 0.20459353 0.07463914\n",
      " 0.075386   0.03105505 0.02747472 0.03854779 0.01858942 0.1125321 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14422106 0.10720674 0.38872876 0.23399947 0.31483207 0.19578296\n",
      " 0.20975174 0.12991884 0.12023504 0.1334364  0.13087881 0.20531462]\n",
      "INFO:root:In epoch 6, loss is 0.17721939086914062\n",
      "INFO:root:Mean generator loss: 0.08277112096548081\n",
      "INFO:root:Mean random guess loss: 0.19377909898757933\n",
      "INFO:root:Mean generator loss Per Feature: [0.03220105 0.01143644 0.24951673 0.12949359 0.20524772 0.07496\n",
      " 0.07441317 0.02734961 0.02474372 0.03482603 0.01692834 0.11213705]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12894759 0.12458435 0.39386047 0.24847577 0.31899694 0.19753415\n",
      " 0.20884778 0.11749768 0.12652354 0.12604993 0.12297089 0.21106014]\n",
      "INFO:root:In epoch 7, loss is 0.15821334719657898\n",
      "INFO:root:Mean generator loss: 0.08148784736792246\n",
      "INFO:root:Mean random guess loss: 0.19884291291236877\n",
      "INFO:root:Mean generator loss Per Feature: [0.03045499 0.01030684 0.24936622 0.12798924 0.20450746 0.07485657\n",
      " 0.07476336 0.02424398 0.02199345 0.03259766 0.01542758 0.11134685]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13665562 0.12085063 0.38367639 0.24247524 0.3190124  0.20309221\n",
      " 0.21052132 0.12261133 0.11977403 0.14630728 0.13499041 0.24614807]\n",
      "INFO:root:In epoch 8, loss is 0.14261603355407715\n",
      "INFO:root:Mean generator loss: 0.08037059505780537\n",
      "INFO:root:Mean random guess loss: 0.1935721755027771\n",
      "INFO:root:Mean generator loss Per Feature: [0.02898724 0.00912812 0.24747614 0.12699141 0.20453818 0.07492353\n",
      " 0.07461548 0.02211138 0.01986436 0.03029848 0.01428244 0.11123039]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12266723 0.11193428 0.38198173 0.24186908 0.31598887 0.20916219\n",
      " 0.21417482 0.12577969 0.11510186 0.12951116 0.12860523 0.22608994]\n",
      "INFO:root:In epoch 9, loss is 0.12968233227729797\n",
      "INFO:root:Mean generator loss: 0.07965045720338822\n",
      "INFO:root:Mean random guess loss: 0.19751827617486317\n",
      "INFO:root:Mean generator loss Per Feature: [0.02783415 0.00848029 0.24799139 0.12673847 0.2050686  0.07521835\n",
      " 0.07406731 0.01935758 0.01822384 0.02823039 0.0131713  0.11142383]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14611647 0.11260822 0.36721999 0.23763114 0.35589662 0.21321928\n",
      " 0.21433623 0.10953752 0.1176272  0.11564719 0.13896942 0.24141003]\n",
      "INFO:root:In epoch 10, loss is 0.11899185925722122\n",
      "INFO:root:Mean generator loss: 0.07894974648952484\n",
      "INFO:root:Mean random guess loss: 0.19278175830841066\n",
      "INFO:root:Mean generator loss Per Feature: [0.02664646 0.00760994 0.24917451 0.12589699 0.20468735 0.07471219\n",
      " 0.07437975 0.01789833 0.01667975 0.02674722 0.012222   0.11074247]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13521634 0.10077277 0.37746932 0.24495398 0.33406133 0.2017808\n",
      " 0.19965274 0.12493205 0.12442382 0.13686777 0.12336755 0.20988262]\n",
      "INFO:root:In epoch 11, loss is 0.10983815044164658\n",
      "INFO:root:Mean generator loss: 0.07813479801019033\n",
      "INFO:root:Mean random guess loss: 0.19599287112553915\n",
      "INFO:root:Mean generator loss Per Feature: [0.02565647 0.00695387 0.24730551 0.1251197  0.20481014 0.07509344\n",
      " 0.07347752 0.01668731 0.01503097 0.02532267 0.01148686 0.11067311]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12589509 0.11768097 0.37769195 0.23701453 0.34745274 0.19850731\n",
      " 0.21090291 0.10936321 0.13090624 0.13223019 0.12343652 0.2408328 ]\n",
      "INFO:root:In epoch 12, loss is 0.10172058641910553\n",
      "INFO:root:Mean generator loss: 0.07773806154727936\n",
      "INFO:root:Mean random guess loss: 0.19011019468307494\n",
      "INFO:root:Mean generator loss Per Feature: [0.02490371 0.00644161 0.24863555 0.12515556 0.20424904 0.07477109\n",
      " 0.07410441 0.01529612 0.01390829 0.02399171 0.01077472 0.11062492]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.11822186 0.12993025 0.33942359 0.25302859 0.32301135 0.21482993\n",
      " 0.21124424 0.10601071 0.11921948 0.12541548 0.12581505 0.21517184]\n",
      "INFO:root:In epoch 13, loss is 0.09497714787721634\n",
      "INFO:root:Mean generator loss: 0.07729283918937048\n",
      "INFO:root:Mean random guess loss: 0.1909858892361323\n",
      "INFO:root:Mean generator loss Per Feature: [0.02423193 0.00601944 0.24846771 0.12446118 0.20480693 0.07499213\n",
      " 0.07410169 0.01399782 0.01284442 0.0230405  0.01019435 0.11035597]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.123383   0.11637007 0.37535088 0.24075705 0.3198285  0.20345135\n",
      " 0.20576069 0.12063117 0.11271718 0.13501615 0.11190655 0.22665808]\n",
      "INFO:root:In epoch 14, loss is 0.0888880118727684\n",
      "INFO:root:Mean generator loss: 0.07701848894357681\n",
      "INFO:root:Mean random guess loss: 0.19207400381565093\n",
      "INFO:root:Mean generator loss Per Feature: [0.02364398 0.00566873 0.24957545 0.12403278 0.2050464  0.07526652\n",
      " 0.0738007  0.01299747 0.01187328 0.0219561  0.00972276 0.1106377 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13332658 0.12060691 0.38237477 0.23318513 0.33515779 0.20181882\n",
      " 0.19486773 0.11900845 0.11728672 0.11240514 0.12927309 0.22557695]\n",
      "INFO:root:In epoch 15, loss is 0.08357712626457214\n",
      "INFO:root:Mean generator loss: 0.07665775914986929\n",
      "INFO:root:Mean random guess loss: 0.19136711061000825\n",
      "INFO:root:Mean generator loss Per Feature: [0.02306972 0.00529813 0.24890484 0.12400069 0.20478719 0.07510094\n",
      " 0.07447538 0.01225332 0.01102992 0.02120552 0.00921268 0.11055479]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13001708 0.12312048 0.36590275 0.23908691 0.33257622 0.19298213\n",
      " 0.2126242  0.1132945  0.12188883 0.13046745 0.12079348 0.21365129]\n",
      "INFO:root:In epoch 16, loss is 0.07909395545721054\n",
      "INFO:root:Mean generator loss: 0.0762094924847285\n",
      "INFO:root:Mean random guess loss: 0.19708048005898793\n",
      "INFO:root:Mean generator loss Per Feature: [0.02240587 0.00504759 0.24846535 0.12375276 0.20444314 0.0747255\n",
      " 0.07391631 0.01153307 0.01025066 0.02055112 0.00881959 0.11060295]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13370629 0.12405103 0.39446167 0.2641556  0.34874974 0.20244825\n",
      " 0.19235299 0.11356777 0.12645976 0.12651252 0.11072789 0.22777225]\n",
      "INFO:root:In epoch 17, loss is 0.0750095546245575\n",
      "INFO:root:Mean generator loss: 0.07597787578900655\n",
      "INFO:root:Mean random guess loss: 0.19735059440135955\n",
      "INFO:root:Mean generator loss Per Feature: [0.02200378 0.00480801 0.24860615 0.12377657 0.20441015 0.07486164\n",
      " 0.07419893 0.0107877  0.0095861  0.01973165 0.00846217 0.11050167]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14381381 0.12122146 0.3693586  0.25096766 0.32520433 0.20493836\n",
      " 0.20837352 0.12569883 0.13496944 0.13055209 0.11470984 0.23839921]\n",
      "INFO:root:In epoch 18, loss is 0.07145769894123077\n",
      "INFO:root:Mean generator loss: 0.07577065328756968\n",
      "INFO:root:Mean random guess loss: 0.1988038758436839\n",
      "INFO:root:Mean generator loss Per Feature: [0.02153044 0.00457995 0.24887347 0.12357934 0.20438926 0.07524707\n",
      " 0.0740065  0.01020702 0.00901504 0.01921289 0.00814372 0.11046312]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.15956978 0.10915743 0.37934574 0.23894354 0.34204787 0.20505822\n",
      " 0.21649745 0.13138915 0.12552615 0.12635018 0.11393796 0.23782301]\n",
      "INFO:root:In epoch 19, loss is 0.06829063594341278\n",
      "INFO:root:Mean generator loss: 0.07552910447120667\n",
      "INFO:root:Mean random guess loss: 0.19260132511456807\n",
      "INFO:root:Mean generator loss Per Feature: [0.02119425 0.00434104 0.24874225 0.12347155 0.20443061 0.07499874\n",
      " 0.07409784 0.00971471 0.0085146  0.01862506 0.00785964 0.11035897]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12171182 0.11257366 0.36718573 0.2617738  0.36036102 0.20387691\n",
      " 0.20772781 0.10875856 0.11399571 0.1223407  0.12708642 0.20382376]\n",
      "INFO:root:In epoch 20, loss is 0.06549075245857239\n",
      "INFO:root:Mean generator loss: 0.07537362078825632\n",
      "INFO:root:Mean random guess loss: 0.20100119312604267\n",
      "INFO:root:Mean generator loss Per Feature: [0.02082253 0.00415926 0.24870032 0.12355508 0.20429813 0.07518951\n",
      " 0.07414223 0.00921846 0.00806023 0.01806159 0.00767013 0.11060597]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13989322 0.12645629 0.40645346 0.24808852 0.34823196 0.20586151\n",
      " 0.20231395 0.12550467 0.12555637 0.14054509 0.11266807 0.23044118]\n",
      "INFO:root:In epoch 21, loss is 0.06292558461427689\n",
      "INFO:root:Mean generator loss: 0.07510631283124287\n",
      "INFO:root:Mean random guess loss: 0.2004337747891744\n",
      "INFO:root:Mean generator loss Per Feature: [0.02052871 0.0040452  0.24834089 0.12330062 0.20429694 0.07462427\n",
      " 0.07395095 0.00876767 0.00764276 0.01770919 0.0074418  0.11062678]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14817523 0.11627909 0.40879732 0.24486771 0.33827492 0.21159091\n",
      " 0.19136983 0.12295508 0.13167481 0.14266726 0.13195603 0.21659711]\n",
      "INFO:root:In epoch 22, loss is 0.06074921414256096\n",
      "INFO:root:Mean generator loss: 0.07512838790814082\n",
      "INFO:root:Mean random guess loss: 0.19156906406084698\n",
      "INFO:root:Mean generator loss Per Feature: [0.02031127 0.00390667 0.2492363  0.12313758 0.20464209 0.07527544\n",
      " 0.07423224 0.00850225 0.00725557 0.01730733 0.0072073  0.11052661]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12655943 0.11801858 0.3818307  0.23006768 0.31866791 0.19035805\n",
      " 0.19892516 0.12286059 0.12744671 0.11596322 0.12787506 0.24025572]\n",
      "INFO:root:In epoch 23, loss is 0.05868120118975639\n",
      "INFO:root:Mean generator loss: 0.07488905986150106\n",
      "INFO:root:Mean random guess loss: 0.19081717630227407\n",
      "INFO:root:Mean generator loss Per Feature: [0.01999412 0.00377769 0.24877709 0.12290626 0.20448512 0.07471204\n",
      " 0.0744279  0.00822721 0.00692784 0.01695792 0.00704804 0.11042744]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12897114 0.11792173 0.35809786 0.22922397 0.32252311 0.18936161\n",
      " 0.20670413 0.12318368 0.14250353 0.11743506 0.12816226 0.22571797]\n",
      "INFO:root:In epoch 24, loss is 0.05691361799836159\n",
      "INFO:root:Mean generator loss: 0.07478252251942953\n",
      "INFO:root:Mean random guess loss: 0.19731739660104117\n",
      "INFO:root:Mean generator loss Per Feature: [0.01971055 0.00363967 0.24855867 0.12296901 0.2046665  0.07497831\n",
      " 0.07416265 0.0079786  0.00661788 0.01660712 0.00687393 0.11062739]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.11478905 0.1171478  0.36418297 0.23903574 0.34920565 0.20818523\n",
      " 0.19779739 0.13655642 0.12631402 0.12548615 0.13205326 0.25705516]\n",
      "INFO:root:In epoch 25, loss is 0.05540080368518829\n",
      "INFO:root:Mean generator loss: 0.0746713454524676\n",
      "INFO:root:Mean random guess loss: 0.1863031913836797\n",
      "INFO:root:Mean generator loss Per Feature: [0.01951079 0.00356778 0.24898625 0.12290105 0.20428342 0.07468503\n",
      " 0.07438698 0.00772837 0.00635823 0.01636015 0.00671935 0.11056876]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12400347 0.1089789  0.38658617 0.22747466 0.31225233 0.19520673\n",
      " 0.20455001 0.12384012 0.10667857 0.12329768 0.10820659 0.21456306]\n",
      "INFO:root:In epoch 26, loss is 0.05400112643837929\n",
      "INFO:root:Mean generator loss: 0.07453847428162892\n",
      "INFO:root:Mean random guess loss: 0.19723031024138132\n",
      "INFO:root:Mean generator loss Per Feature: [0.01929694 0.00347955 0.24869865 0.12274433 0.20459806 0.07487298\n",
      " 0.07394145 0.00756225 0.00610272 0.01609328 0.00659623 0.11047525]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.1175994  0.11618624 0.37295087 0.25368252 0.33965602 0.19068317\n",
      " 0.19848773 0.13001672 0.14128794 0.1301073  0.12969753 0.24640825]\n",
      "INFO:root:In epoch 27, loss is 0.052774716168642044\n",
      "INFO:root:Mean generator loss: 0.07446142037709554\n",
      "INFO:root:Mean random guess loss: 0.1907023996114731\n",
      "INFO:root:Mean generator loss Per Feature: [0.01914877 0.00340859 0.24849219 0.12299552 0.20466452 0.07478153\n",
      " 0.07398859 0.00740722 0.00590411 0.01587801 0.00647538 0.11039262]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14252641 0.10447213 0.39442521 0.21420202 0.32100686 0.20904864\n",
      " 0.21180803 0.11657768 0.11277231 0.12652454 0.11723001 0.21783493]\n",
      "INFO:root:In epoch 28, loss is 0.0515630804002285\n",
      "INFO:root:Mean generator loss: 0.07433834373950958\n",
      "INFO:root:Mean random guess loss: 0.1908874750137329\n",
      "INFO:root:Mean generator loss Per Feature: [0.01896451 0.00332599 0.24861103 0.1228441  0.20405819 0.07491916\n",
      " 0.07391951 0.0072463  0.00566815 0.01567294 0.00637275 0.11045748]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12233343 0.11031056 0.37589373 0.23677733 0.33402987 0.20431032\n",
      " 0.22393177 0.11294948 0.11609479 0.1170038  0.11284809 0.2241665 ]\n",
      "INFO:root:In epoch 29, loss is 0.050560396164655685\n",
      "INFO:root:Mean generator loss: 0.074278491238753\n",
      "INFO:root:Mean random guess loss: 0.18667801320552826\n",
      "INFO:root:Mean generator loss Per Feature: [0.01877006 0.00326657 0.24822732 0.12276309 0.20449721 0.07489488\n",
      " 0.07396998 0.00705286 0.00551567 0.01548603 0.00624158 0.11065661]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12748633 0.12682331 0.34276783 0.2431612  0.31961477 0.1882645\n",
      " 0.2121981  0.11247034 0.10399594 0.11162052 0.1269701  0.22476323]\n",
      "INFO:root:In epoch 30, loss is 0.04951607435941696\n",
      "INFO:root:Mean generator loss: 0.07430904259284338\n",
      "INFO:root:Mean random guess loss: 0.1928090214729309\n",
      "INFO:root:Mean generator loss Per Feature: [0.01865778 0.00321082 0.24882654 0.12279316 0.20447214 0.07507338\n",
      " 0.07423542 0.00698391 0.00535729 0.01526366 0.006182   0.1106524 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13190709 0.11866683 0.3638439  0.23747261 0.3313049  0.19710448\n",
      " 0.21308938 0.12619405 0.10212809 0.1373429  0.12428531 0.23036874]\n",
      "INFO:root:In epoch 31, loss is 0.04878413677215576\n",
      "INFO:root:Mean generator loss: 0.07418960432211558\n",
      "INFO:root:Mean random guess loss: 0.18914446334044138\n",
      "INFO:root:Mean generator loss Per Feature: [0.01852913 0.00317259 0.24798303 0.12282721 0.2049937  0.07492706\n",
      " 0.07414742 0.00689643 0.00517485 0.01513148 0.00609806 0.11039431]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12245227 0.10327554 0.35097085 0.2507739  0.31833537 0.20964863\n",
      " 0.19477137 0.11197929 0.12012147 0.13360564 0.1267331  0.22706609]\n",
      "INFO:root:In epoch 32, loss is 0.048056282103061676\n",
      "INFO:root:Mean generator loss: 0.07410405824581782\n",
      "INFO:root:Mean random guess loss: 0.19109240174293518\n",
      "INFO:root:Mean generator loss Per Feature: [0.01834316 0.0031098  0.24838156 0.12269225 0.20489469 0.07470692\n",
      " 0.07389383 0.00676544 0.00502648 0.0149842  0.00601546 0.11043491]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.11581615 0.10365057 0.37379805 0.24287858 0.33516973 0.19711894\n",
      " 0.22679241 0.12533385 0.13408003 0.12711088 0.11645972 0.19489992]\n",
      "INFO:root:In epoch 33, loss is 0.047249507158994675\n",
      "INFO:root:Mean generator loss: 0.0740439752737681\n",
      "INFO:root:Mean random guess loss: 0.19598776400089263\n",
      "INFO:root:Mean generator loss Per Feature: [0.01824577 0.00307593 0.24821976 0.12288512 0.20434255 0.07465624\n",
      " 0.07428774 0.00668717 0.00491307 0.01488285 0.00597822 0.11035328]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13415326 0.12058821 0.39277321 0.25370639 0.34110715 0.19230522\n",
      " 0.20971867 0.11348562 0.13439399 0.11894248 0.11263088 0.22804809]\n",
      "INFO:root:In epoch 34, loss is 0.04658618941903114\n",
      "INFO:root:Mean generator loss: 0.07406848718722661\n",
      "INFO:root:Mean random guess loss: 0.19209184348583222\n",
      "INFO:root:Mean generator loss Per Feature: [0.0181922  0.00302933 0.24882871 0.12272984 0.20470458 0.07485612\n",
      " 0.07395978 0.00663064 0.00479641 0.01475164 0.0059059  0.1104367 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13759334 0.11764711 0.37328322 0.24056103 0.34399292 0.19700591\n",
      " 0.19210451 0.12214681 0.10125256 0.12834933 0.11699833 0.23416702]\n",
      "INFO:root:In epoch 35, loss is 0.04603305086493492\n",
      "INFO:root:Mean generator loss: 0.07404582500457764\n",
      "INFO:root:Mean random guess loss: 0.18890260855356852\n",
      "INFO:root:Mean generator loss Per Feature: [0.01805853 0.00300361 0.24852043 0.12285554 0.20463077 0.07479654\n",
      " 0.07417371 0.00655114 0.0046739  0.01467129 0.00584167 0.11077277]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.1332482  0.10891837 0.35820103 0.2396554  0.35043683 0.21042352\n",
      " 0.1986611  0.10408891 0.11552099 0.11429785 0.12092412 0.21245493]\n",
      "INFO:root:In epoch 36, loss is 0.04556259140372276\n",
      "INFO:root:Mean generator loss: 0.07399775485197703\n",
      "INFO:root:Mean random guess loss: 0.19031398892402648\n",
      "INFO:root:Mean generator loss Per Feature: [0.01798841 0.00296874 0.24864803 0.12280272 0.2043958  0.07515376\n",
      " 0.07403641 0.0064875  0.00459395 0.01455967 0.00581163 0.11052641]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13094926 0.12394234 0.36980277 0.22805286 0.32017056 0.20395183\n",
      " 0.20352931 0.12764331 0.12429351 0.12141917 0.11428738 0.21572556]\n",
      "INFO:root:In epoch 37, loss is 0.0450732596218586\n",
      "INFO:root:Mean generator loss: 0.07389410783847174\n",
      "INFO:root:Mean random guess loss: 0.18927416304747263\n",
      "INFO:root:Mean generator loss Per Feature: [0.01791683 0.00295608 0.24852556 0.1225162  0.20438407 0.07481261\n",
      " 0.07386623 0.00642785 0.00450902 0.01446676 0.0057606  0.11058749]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12290762 0.11887467 0.35275502 0.2527452  0.32284979 0.20533758\n",
      " 0.20233413 0.1199945  0.11921307 0.1103092  0.11044985 0.23351929]\n",
      "INFO:root:In epoch 38, loss is 0.04473589360713959\n",
      "INFO:root:Mean generator loss: 0.07384025851885477\n",
      "INFO:root:Mean random guess loss: 0.19065221746762592\n",
      "INFO:root:Mean generator loss Per Feature: [0.01780478 0.00294088 0.24823941 0.12258453 0.20444284 0.07474468\n",
      " 0.07402067 0.00639367 0.0044156  0.01437022 0.00571321 0.1104126 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13250519 0.11476213 0.38962472 0.23764693 0.32838699 0.18642521\n",
      " 0.19605977 0.11623813 0.10990887 0.12593086 0.11686986 0.23346794]\n",
      "INFO:root:In epoch 39, loss is 0.044224850833415985\n",
      "INFO:root:Mean generator loss: 0.07385726124048234\n",
      "INFO:root:Mean random guess loss: 0.19134621918201447\n",
      "INFO:root:Mean generator loss Per Feature: [0.01774957 0.00291395 0.24864273 0.12264705 0.20430744 0.07483931\n",
      " 0.07412298 0.00634966 0.00434322 0.01428958 0.00565873 0.1104229 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14537424 0.11147673 0.36840674 0.23053081 0.33735458 0.19843024\n",
      " 0.1996378  0.1095308  0.1173287  0.12127147 0.11910939 0.2377032 ]\n",
      "INFO:root:In epoch 40, loss is 0.043853528797626495\n",
      "INFO:root:Mean generator loss: 0.07390523552894593\n",
      "INFO:root:Mean random guess loss: 0.1890425870815913\n",
      "INFO:root:Mean generator loss Per Feature: [0.0176801  0.00289905 0.24876066 0.12284575 0.20490251 0.07479035\n",
      " 0.07406406 0.0063038  0.00426887 0.01419107 0.0056265  0.1105301 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14453543 0.11106809 0.35966395 0.24997874 0.3272609  0.18810063\n",
      " 0.19531823 0.11786747 0.11805772 0.1350472  0.10852313 0.21308953]\n",
      "INFO:root:In epoch 41, loss is 0.04353076592087746\n",
      "INFO:root:Mean generator loss: 0.07389974047740301\n",
      "INFO:root:Mean random guess loss: 0.19322621325651804\n",
      "INFO:root:Mean generator loss Per Feature: [0.01763241 0.00287018 0.24900901 0.12278661 0.20488983 0.07497145\n",
      " 0.0738031  0.0062688  0.00420219 0.01415761 0.0055907  0.11061501]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12897105 0.1203793  0.38858005 0.25811466 0.31733988 0.19918797\n",
      " 0.20743456 0.11428398 0.12224589 0.13109935 0.11330204 0.21777583]\n",
      "INFO:root:In epoch 42, loss is 0.04322415962815285\n",
      "INFO:root:Mean generator loss: 0.07381143818298976\n",
      "INFO:root:Mean random guess loss: 0.1917433559894562\n",
      "INFO:root:Mean generator loss Per Feature: [0.01755814 0.00287418 0.24823679 0.12265204 0.20465672 0.07502759\n",
      " 0.07418799 0.0062621  0.00412617 0.0140884  0.00555958 0.11050758]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14558731 0.11863108 0.37160645 0.24999051 0.30576895 0.20708065\n",
      " 0.20321308 0.13133031 0.12223796 0.12409237 0.11237272 0.20900889]\n",
      "INFO:root:In epoch 43, loss is 0.042896803468465805\n",
      "INFO:root:Mean generator loss: 0.07380602757136027\n",
      "INFO:root:Mean random guess loss: 0.1882809857527415\n",
      "INFO:root:Mean generator loss Per Feature: [0.01749352 0.00286274 0.24873353 0.12263079 0.20459856 0.07480996\n",
      " 0.07415353 0.00624222 0.00408634 0.01401084 0.00552871 0.1105216 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.1398279  0.12286444 0.35653828 0.22313799 0.30612191 0.19927018\n",
      " 0.19007041 0.12394916 0.10633347 0.13598829 0.1236611  0.23160871]\n",
      "INFO:root:In epoch 44, loss is 0.042603686451911926\n",
      "INFO:root:Mean generator loss: 0.07374437153339386\n",
      "INFO:root:Mean random guess loss: 0.19630414446194966\n",
      "INFO:root:Mean generator loss Per Feature: [0.01743304 0.00284501 0.24843342 0.1227012  0.20460409 0.07479621\n",
      " 0.07393834 0.00623193 0.00402824 0.01396795 0.00550503 0.11044799]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14162697 0.11754006 0.38358958 0.25537819 0.33727535 0.19714079\n",
      " 0.20172137 0.10749651 0.13147283 0.12779096 0.12575134 0.22886576]\n",
      "INFO:root:In epoch 45, loss is 0.04234771430492401\n",
      "INFO:root:Mean generator loss: 0.07369583199421564\n",
      "INFO:root:Mean random guess loss: 0.1910321484009425\n",
      "INFO:root:Mean generator loss Per Feature: [0.0174181  0.0028333  0.24833764 0.12245033 0.20454992 0.07464982\n",
      " 0.07400177 0.00618684 0.00397661 0.01389604 0.00547872 0.11057088]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14531171 0.11478501 0.36879606 0.23645162 0.3122047  0.19849435\n",
      " 0.19970965 0.11037418 0.12453678 0.14706534 0.10192861 0.23272782]\n",
      "INFO:root:In epoch 46, loss is 0.04216013103723526\n",
      "INFO:root:Mean generator loss: 0.07374823490778605\n",
      "INFO:root:Mean random guess loss: 0.19089233378569284\n",
      "INFO:root:Mean generator loss Per Feature: [0.01737328 0.00281941 0.24858473 0.12272097 0.20456055 0.07503959\n",
      " 0.07415534 0.00617415 0.00392295 0.01388464 0.00545934 0.11028384]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12116243 0.12348227 0.39319544 0.23682142 0.32572872 0.18564487\n",
      " 0.19498761 0.11342546 0.12169135 0.13987462 0.11011208 0.22458171]\n",
      "INFO:root:In epoch 47, loss is 0.04200047254562378\n",
      "INFO:root:Mean generator loss: 0.07369101891915003\n",
      "INFO:root:Mean random guess loss: 0.1894046723842621\n",
      "INFO:root:Mean generator loss Per Feature: [0.01730119 0.00280273 0.24831811 0.12251611 0.20467802 0.07506575\n",
      " 0.0737738  0.00614553 0.00388769 0.0138372  0.0054335  0.11053259]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12716683 0.11770178 0.34510341 0.23476521 0.32163938 0.22324582\n",
      " 0.1977268  0.11757336 0.12477636 0.11535186 0.09880811 0.24899712]\n",
      "INFO:root:In epoch 48, loss is 0.04175565391778946\n",
      "INFO:root:Mean generator loss: 0.07372399022181829\n",
      "INFO:root:Mean random guess loss: 0.19865243832270305\n",
      "INFO:root:Mean generator loss Per Feature: [0.01725451 0.00278963 0.24874199 0.12266568 0.20452243 0.0749344\n",
      " 0.07412582 0.00614409 0.00383511 0.01379287 0.00541865 0.11046269]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13687859 0.11678038 0.39205315 0.24865946 0.32484815 0.19290135\n",
      " 0.20741246 0.12979456 0.12296005 0.13846674 0.12563323 0.24744113]\n",
      "INFO:root:In epoch 49, loss is 0.04155345261096954\n",
      "INFO:root:Mean generator loss: 0.0737084060907364\n",
      "INFO:root:Mean random guess loss: 0.1925258179505666\n",
      "INFO:root:Mean generator loss Per Feature: [0.01723553 0.0027945  0.24869545 0.12277468 0.20450833 0.07480799\n",
      " 0.07407734 0.00610648 0.00380398 0.01375872 0.00539873 0.11053914]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14388044 0.11511562 0.36927224 0.24204508 0.3325198  0.20062139\n",
      " 0.20981873 0.11658971 0.12082302 0.12503636 0.09512223 0.23946525]\n",
      "INFO:root:In epoch 50, loss is 0.04135854169726372\n",
      "INFO:root:Mean generator loss: 0.0737077866991361\n",
      "INFO:root:Mean random guess loss: 0.19130743145942689\n",
      "INFO:root:Mean generator loss Per Feature: [0.01720911 0.0027954  0.24837931 0.1227576  0.20465254 0.0751685\n",
      " 0.07393617 0.00610931 0.00377546 0.01371585 0.00537683 0.11061734]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14938397 0.12047759 0.37050833 0.24494789 0.31593564 0.19237914\n",
      " 0.20661842 0.1033367  0.11660166 0.1285683  0.11412913 0.23280239]\n",
      "INFO:root:In epoch 51, loss is 0.04119042679667473\n",
      "INFO:root:Mean generator loss: 0.07364718864361446\n",
      "INFO:root:Mean random guess loss: 0.19636088311672212\n",
      "INFO:root:Mean generator loss Per Feature: [0.01716068 0.00278214 0.24837064 0.12261752 0.20456496 0.0747943\n",
      " 0.07401548 0.00607121 0.00372591 0.01370308 0.00535792 0.11060242]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14019388 0.11729263 0.3765083  0.24960874 0.33629463 0.20141551\n",
      " 0.20001669 0.11711468 0.12497309 0.14658424 0.1193053  0.22702294]\n",
      "INFO:root:In epoch 52, loss is 0.04114902392029762\n",
      "INFO:root:Mean generator loss: 0.07362695932388305\n",
      "INFO:root:Mean random guess loss: 0.19728607634703318\n",
      "INFO:root:Mean generator loss Per Feature: [0.01710952 0.0027616  0.24840067 0.12262671 0.20446746 0.07493015\n",
      " 0.07372561 0.00605565 0.0037013  0.01364013 0.00535027 0.11075447]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14452653 0.11586953 0.37314606 0.23425842 0.32763856 0.20881099\n",
      " 0.20536082 0.12069691 0.12891226 0.13201324 0.12927405 0.2469255 ]\n",
      "INFO:root:In epoch 53, loss is 0.040975574404001236\n",
      "INFO:root:Mean generator loss: 0.07364115118980408\n",
      "INFO:root:Mean random guess loss: 0.19419338603814443\n",
      "INFO:root:Mean generator loss Per Feature: [0.01710796 0.00277514 0.24841732 0.12271463 0.20436584 0.07494192\n",
      " 0.07409554 0.00608656 0.00366428 0.01363663 0.00533693 0.11055107]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13625746 0.11342194 0.41545855 0.22329042 0.35209146 0.20403004\n",
      " 0.18789872 0.14002187 0.12256846 0.11552203 0.11054837 0.2092113 ]\n",
      "INFO:root:In epoch 54, loss is 0.04071466252207756\n",
      "INFO:root:Mean generator loss: 0.07360250999530156\n",
      "INFO:root:Mean random guess loss: 0.1937968631585439\n",
      "INFO:root:Mean generator loss Per Feature: [0.01705825 0.00276027 0.24819084 0.12265079 0.2046448  0.07476304\n",
      " 0.07397457 0.00607223 0.00364254 0.01358449 0.00531431 0.11057399]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12191205 0.12568247 0.38041707 0.25274911 0.31516932 0.21093725\n",
      " 0.20353024 0.12015032 0.12511629 0.13481723 0.11940419 0.21567685]\n",
      "INFO:root:In epoch 55, loss is 0.04073416814208031\n",
      "INFO:root:Mean generator loss: 0.07360593130191168\n",
      "INFO:root:Mean random guess loss: 0.19414722422758737\n",
      "INFO:root:Mean generator loss Per Feature: [0.01705594 0.00275125 0.24841242 0.12267486 0.20464271 0.07485488\n",
      " 0.07382612 0.00605683 0.00361156 0.01359452 0.00530342 0.11048664]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14016935 0.12980105 0.36773681 0.2451573  0.3374513  0.19840237\n",
      " 0.19907418 0.12488536 0.11417518 0.1202239  0.11360778 0.2390821 ]\n",
      "INFO:root:In epoch 56, loss is 0.0405782051384449\n",
      "INFO:root:Mean generator loss: 0.07360531191031137\n",
      "INFO:root:Mean random guess loss: 0.19133027990659077\n",
      "INFO:root:Mean generator loss Per Feature: [0.01701816 0.00273879 0.24822257 0.12280967 0.20448801 0.07491995\n",
      " 0.0740771  0.0060619  0.00357613 0.01356638 0.005287   0.1104981 ]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12341041 0.11783713 0.38164671 0.21948479 0.32091077 0.20829884\n",
      " 0.19960439 0.12312601 0.12254698 0.12197015 0.12968817 0.22743899]\n",
      "INFO:root:In epoch 57, loss is 0.04050629585981369\n",
      "INFO:root:Mean generator loss: 0.07364108016093572\n",
      "INFO:root:Mean random guess loss: 0.19095749656359354\n",
      "INFO:root:Mean generator loss Per Feature: [0.01700818 0.0027395  0.24866156 0.12268912 0.20489993 0.07466924\n",
      " 0.0741377  0.00605342 0.00356254 0.01356019 0.00527944 0.11043212]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.12500559 0.12134305 0.38287093 0.23953061 0.29339035 0.21666903\n",
      " 0.20427092 0.13188029 0.10904996 0.12637151 0.10843072 0.23267696]\n",
      "INFO:root:In epoch 58, loss is 0.0403231717646122\n",
      "INFO:root:Mean generator loss: 0.07364243616660436\n",
      "INFO:root:Mean random guess loss: 0.19258622427781422\n",
      "INFO:root:Mean generator loss Per Feature: [0.01697155 0.00274033 0.24866842 0.12263007 0.20468897 0.07502722\n",
      " 0.07403809 0.00603688 0.00353716 0.01354712 0.0052756  0.11054784]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.13848728 0.11118498 0.38436684 0.25493208 0.31286863 0.20345237\n",
      " 0.1999485  0.12529411 0.11272025 0.14036673 0.10814213 0.21927078]\n",
      "INFO:root:In epoch 59, loss is 0.040299829095602036\n",
      "INFO:root:Mean generator loss: 0.0735635722676913\n",
      "INFO:root:Mean random guess loss: 0.19322728216648102\n",
      "INFO:root:Mean generator loss Per Feature: [0.01696526 0.00273383 0.24830768 0.12261036 0.20460417 0.07474598\n",
      " 0.07410377 0.00603565 0.00352025 0.01351011 0.00526608 0.11035972]\n",
      "INFO:root:Mean random guess loss Per Feature: [0.14009716 0.11192074 0.3806747  0.24659446 0.32629624 0.21798824\n",
      " 0.20516709 0.12413002 0.11199382 0.12346999 0.11282907 0.21756592]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [array(0.36142364, dtype=float32)],\n",
       " 'train_BinaryAccuracy': [array(0.8420907, dtype=float32)],\n",
       " 'train_BinaryPrecision': [array(0.08955224, dtype=float32)],\n",
       " 'val_loss': [array(0.17533527, dtype=float32)],\n",
       " 'val_BinaryAccuracy': [array(0.8729282, dtype=float32)],\n",
       " 'val_BinaryPrecision': [array(0., dtype=float32)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_model.fit(\n",
    "    train_fea,\n",
    "    train_label,\n",
    "    validation_data=(test_fea, test_label),\n",
    "    epochs=1,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    random_seed=1234,\n",
    "    dataset_builder=None,\n",
    "    callbacks=callback_dict, # 暂时注释掉，callback完成后恢复 @caibei\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cdaa4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的base model？\n",
    "sl_model.save_model(base_model_path=model_save_path,\n",
    "                    fuse_model_path=fuse_model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6352a-38da-4d13-9357-22d5835fa2a7",
   "metadata": {},
   "source": [
    "## 总结\n",
    "本文通过 UCI Sensorless Drive Diagnosis 数据集上的特征攻击任务来演示了如何通过隐语来使用 FeatureInferenceAttack。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b18f1-58b6-4d0f-be81-bc3da09e6a13",
   "metadata": {},
   "source": [
    "您可以：\n",
    "\n",
    "1. 下载并拆分数据集，准备训练、攻击使用的数据\n",
    "2. 定义拆分模型结构及 SL Model\n",
    "3. 定义 attacker_builder，在其中定义攻击需要的 data_builder 和 FeatureInfereceAttacker\n",
    "4. 调用 SL Model 进行训练攻击\n",
    "\n",
    "您可以在自己的数据集上进行尝试，如有任何问题，可以在 github 进行训练即可。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-sf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
