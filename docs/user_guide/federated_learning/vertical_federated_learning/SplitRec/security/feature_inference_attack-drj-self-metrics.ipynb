{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325403a3-9be9-403f-a44f-36d20054789a",
   "metadata": {},
   "source": [
    "# SplitRec：在隐语拆分学习中使用 FeatureInferenceAttack\n",
    "在联邦学习中，攻击者可以通过监听训练模型过程中传输的数值和梯度信息，攻击对方模型或数据，在一定程度上推理出有用信息，造成信息泄露。\n",
    "\n",
    "本文考虑两方拆分学习中的特征推理攻击，将介绍[《Feature Inference Attacks on Model Predictions in Vertical Federated Learning》](https://arxiv.org/abs/2010.10152)中的 GRN 攻击方法在隐语中的使用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b04cd-77dc-4fa6-937d-4a1f3b9e1f16",
   "metadata": {},
   "source": [
    "## Feature Inference Attack with Generative Regression Network\n",
    "特征推理攻击中，有标签的一方作为攻击方，推测对方的特征。在联邦模型训练之后，GRN 攻击方法通过一个生成回归网络（Generator Model）预测对方特征，并通过不断缩小预测特征在联邦模型的输出值和真实联邦模型输出值的差距，训练 Genertor Model，因而可以预测对方特征，如下图所示。\n",
    "\n",
    "![fia0](resources/fia0.png)\n",
    "\n",
    "其中 Generator Model 具体训练步骤如下：\n",
    "\n",
    "1. 将攻击方特征（蓝色）和随机生成的数据（橙色）输入到 Generator Model 中，输出值作为预测的对方特征\n",
    "2. 将攻击方特征和预测的对方特征输入已经训完的联邦模型中，计算 logit 输出\n",
    "3. 利用步骤 2 中输出的 logit 与真实 logit（攻击方特征和对方真实特征输入联邦模型计算的 logit）计算损失\n",
    "4. 对得到的损失进行反向传播，更新 Generator Model 参数\n",
    "\n",
    "算法伪代码如下：\n",
    "\n",
    "![fia1](resources/fia1.png)\n",
    "\n",
    "loss 函数定义如下：\n",
    "\n",
    "![fia2](resources/fia2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883eac32-bce1-435e-9922-98fd944c4e4b",
   "metadata": {},
   "source": [
    "## 隐语中的攻击方法实现\n",
    "在隐语中攻击方法的实现是通过 callback 机制来完成。攻击算法基类 CallBack 位于 secretflow/ml/nn/sl/backend/torch/callback.py，我们在联邦模型训练的以下几个节点提供 hook，不同攻击方法可以通过将攻击算法实现在对应节点的 hook， 使攻击逻辑注入到联邦模型的训练过程中。\n",
    "\n",
    "- on_train_begin\n",
    "- on_train_end\n",
    "- on_epoch_begin\n",
    "- on_epoch_end\n",
    "- on_batch_begin\n",
    "- on_batch_end\n",
    "\n",
    "用户如果需要实现自定义的攻击方法，需要\n",
    "\n",
    "1. 定义 CustomAttacker 继承基类 Callback，将攻击逻辑实现到对应的 hook 函数中\n",
    "2. 定义 attacker_builder 函数将构建 attacker 写到其中\n",
    "3. 与普通 Split Learning 模型训练一样定义 sl_model, 并在调用 sl_model.fit() 时，将 callback_dict {party -> attacker_builder} 传入 callbacks 参数即可\n",
    "\n",
    "其中步骤 1 可以参考隐语中已有的 FeatureInferenceAttacker/LabelInferenceAttacker，步骤 2 和 3 可参考下面 FeatureInferenceAttacker 的使用方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9a8f4-7335-4380-a8ab-f10d93548382",
   "metadata": {},
   "source": [
    "## Feature Inferece Attack 的隐语封装\n",
    "我们在隐语中提供了多种攻击方法的封装。对于论文中的攻击方法，我们提供了 FeatureInferenceAttacker 封装，具体使用可以参考以下代码。\n",
    "\n",
    "首先和一般 Split Learning 模型训练一样，我们将进行数据处理，并定义一个 SLModel。\n",
    "\n",
    "然后定义调用 FeatureInferenceAttacker 的 attacker_builder，并在 SLModel fit 时将 attacker_builder 传入进行训练和攻击。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d8a72-1c4f-40b9-bbea-2e9c6ca8e86a",
   "metadata": {},
   "source": [
    "## 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adf7fd9-cf8c-4dad-913f-512d3bfedade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.7.0b0\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "# sf.init(['alice', 'bob'], address=\"local\")\n",
    "sf.init(['alice', 'bob'], address=\"local\", debug_mode=True)\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "device_y = alice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afcf4b7-c795-4c12-b725-7607f5b15018",
   "metadata": {},
   "source": [
    "## 数据集介绍\n",
    "这里我们使用 UCI Sensorless Drive Diagnosis 数据集，该数据集有 48 维特征 11 分类。\n",
    "\n",
    "这里我们对数据进行纵向切分，攻击方持有 28 维特征和 label，被攻击方持有 20 维特征。\n",
    "\n",
    "[数据集官网](http://archive.ics.uci.edu/dataset/325/dataset+for+sensorless+drive+diagnosis)\n",
    "\n",
    "这里可以下载论文代码数据集： [drive_cleaned.csv](https://raw.githubusercontent.com/xinjianluo/featureinference-vfl/master/datasets/drive_cleaned.csv)\n",
    "\n",
    "或直接使用我们提供的 demo 数据 drive_cleaned_demo.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5affd8-8fbc-4fdb-9d1c-ff73a0a18d82",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2468168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.data.core.agent.PartitionAgent'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.data.core.agent.PartitionAgent'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.data.core.agent.PartitionAgent'> with party alice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
      "data.dtypes:  {'age': dtype('float32'), 'job': dtype('float32'), 'marital': dtype('float32'), 'education': dtype('float32'), 'default': dtype('float32'), 'balance': dtype('float32'), 'housing': dtype('float32'), 'loan': dtype('float32'), 'contact': dtype('float32'), 'day': dtype('float32'), 'month': dtype('float32'), 'duration': dtype('float32'), 'campaign': dtype('float32'), 'pdays': dtype('float32'), 'previous': dtype('float32'), 'poutcome': dtype('float32')}\n",
      "label.dtypes:  {'y': dtype('float32')}\n",
      "3616\n",
      "type(bob_mean):  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengruijun/miniconda3/envs/drj-sf/lib/python3.10/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/dengruijun/miniconda3/envs/drj-sf/lib/python3.10/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 分割alice和bob的数据集的schema（不是数据集本身）\n",
    "\n",
    "from secretflow.utils.simulation.datasets import load_bank_marketing\n",
    "\n",
    "# Alice has the first four features,\n",
    "# while bob has the left features\n",
    "data = load_bank_marketing(parts={alice: (0, 4), bob: (4, 16)}, axis=1)\n",
    "# Alice holds the label.\n",
    "label = load_bank_marketing(parts={alice: (16, 17)}, axis=1)\n",
    "\n",
    "from secretflow.preprocessing.scaler import MinMaxScaler\n",
    "from secretflow.preprocessing.encoder import LabelEncoder\n",
    "\n",
    "# 类别类编码\n",
    "encoder = LabelEncoder()\n",
    "data['job'] = encoder.fit_transform(data['job'])\n",
    "data['marital'] = encoder.fit_transform(data['marital'])\n",
    "data['education'] = encoder.fit_transform(data['education'])\n",
    "data['default'] = encoder.fit_transform(data['default'])\n",
    "data['housing'] = encoder.fit_transform(data['housing'])\n",
    "data['loan'] = encoder.fit_transform(data['loan'])\n",
    "data['contact'] = encoder.fit_transform(data['contact'])\n",
    "data['poutcome'] = encoder.fit_transform(data['poutcome'])\n",
    "data['month'] = encoder.fit_transform(data['month'])\n",
    "label = encoder.fit_transform(label)\n",
    "\n",
    "# 归一化、 打印数据信息 \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "# data.astype('float32')\n",
    "# print('type(data)=', type(data))\n",
    "print(data.columns)\n",
    "# print(data['job'].loc[0:0])\n",
    "\n",
    "# print(data[alice].shape)\n",
    "# print(data)\n",
    "# print(data.partitions)\n",
    "# print(data.columns) # alice和bob的数据集的列名（总的列表）\n",
    "# print(data.partition_columns) # alice和bob的数据集的列名（分别）\n",
    "# print(\"data.dtypes: \",data.dtypes)\n",
    "# print('label.dtypes: ', label.dtypes)\n",
    "\n",
    "# 转换dtypes\n",
    "# float64 to float32\n",
    "float64_colomns = data.select_dtypes(include=['float64']).columns\n",
    "print(float64_colomns)\n",
    "data[float64_colomns] = data[float64_colomns].astype('float32')\n",
    "\n",
    "label=label.astype('float32')\n",
    "\n",
    "print(\"data.dtypes: \",data.dtypes)\n",
    "print(\"label.dtypes: \",label.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "# 切分数据集（训练&测试）\n",
    "from secretflow.data.split import train_test_split\n",
    "\n",
    "random_state = 1234\n",
    "train_fea, test_fea, = train_test_split(\n",
    "    data, train_size=0.8, random_state=random_state\n",
    ")\n",
    "train_label, test_label = train_test_split(\n",
    "    label, train_size=0.8, random_state=random_state\n",
    ")\n",
    "\n",
    "print(train_fea.values.partition_shape()[alice][0],) # 总的样本数目\n",
    "\n",
    "# 获取 data feature mean\n",
    "mean_attr = data.mean() # 样本均值\n",
    "# bob_mean = sf.reveal(mean_attr.partitions[bob].data).values\n",
    "bob_mean = mean_attr[4:].values\n",
    "print('type(bob_mean): ', type(bob_mean))\n",
    "# print('bob_mean: ', bob_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d946f8-0038-4c59-b804-a119a016fc2a",
   "metadata": {},
   "source": [
    "## 定义 SL 模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf15a00-2622-4d2b-865f-c5bbedf08797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from secretflow.ml.nn.core.torch import BaseModule\n",
    "\n",
    "\n",
    "class SLBaseNet(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, output_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.output_num_value = output_dim\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "    def output_num(self): # 学习 secretflow/ml/nn/applications/sl_dnn_torch.py\n",
    "        return 1\n",
    "\n",
    "class SLFuseModel(BaseModule):\n",
    "    def __init__(self,input_dim, output_dim, party_num):\n",
    "        super().__init__()\n",
    "\n",
    "        # layers = []\n",
    "        # for i in range(party_num):\n",
    "            # layers.append(nn.Linear(input_dim, output_dim))\n",
    "        nn_layers = []\n",
    "        self.total_input_dim = input_dim * party_num\n",
    "        self.fc1 = nn.Linear(self.total_input_dim, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.cat(x,dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ac046-96a7-4aa4-9a01-46394e30b1fc",
   "metadata": {},
   "source": [
    "## 定义 SL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d7ca2d-c10d-4ccb-8340-ba9fb799cafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "# torch相关\n",
    "from secretflow.ml.nn.core.torch import (\n",
    "    metric_wrapper,\n",
    "    optim_wrapper,\n",
    "    BaseModule,\n",
    "    TorchModel,\n",
    ")\n",
    "from torchmetrics import Accuracy, Precision\n",
    "from secretflow.security.aggregation import SecureAggregator\n",
    "from secretflow.utils.simulation.datasets import load_mnist\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "from secretflow.ml.nn import SLModel\n",
    "\n",
    "hidden_size = 64\n",
    "\n",
    "def model_base_alice_fn():\n",
    "    def create_model():\n",
    "        return SLBaseNet(input_dim=4, output_dim=hidden_size)\n",
    "    return create_model\n",
    "\n",
    "def model_base_bob_fn():\n",
    "    def create_model():\n",
    "        return SLBaseNet(input_dim=12, output_dim=hidden_size)\n",
    "    return create_model\n",
    "\n",
    "model_base_alice = TorchModel(\n",
    "    model_fn=model_base_alice_fn(),\n",
    "    loss_fn=nn.BCELoss,\n",
    "    optim_fn = optim_wrapper(optim.Adam),\n",
    "    metrics = [\n",
    "    metric_wrapper(Accuracy, task='binary',),\n",
    "    metric_wrapper(Precision, task='binary',),\n",
    "    ],\n",
    "    # input_dim=4, output_dim=hidden_size,\n",
    "    )\n",
    "\n",
    "model_base_bob = TorchModel(\n",
    "    model_fn=model_base_bob_fn(),\n",
    "    loss_fn=nn.BCELoss,\n",
    "    optim_fn = optim_wrapper(optim.Adam),\n",
    "    metrics = [\n",
    "    metric_wrapper(Accuracy, task='binary',),\n",
    "    metric_wrapper(Precision, task='binary',),\n",
    "    ],\n",
    "    # input_dim=12, output_dim=hidden_size,\n",
    "    )\n",
    "\n",
    "def model_fuse_fn():\n",
    "    def create_model():\n",
    "        return SLFuseModel(input_dim=64, output_dim=1, party_num=2)\n",
    "    return create_model\n",
    "\n",
    "fuse_model = TorchModel(\n",
    "    model_fn=model_fuse_fn(),\n",
    "    loss_fn=nn.BCELoss,\n",
    "    optim_fn = optim_wrapper(optim.Adam),\n",
    "    metrics = [\n",
    "    metric_wrapper(Accuracy, task='binary',),\n",
    "    metric_wrapper(Precision, task='binary',),\n",
    "    ],\n",
    "    # input_dim=64, output_dim=1, party_num=2,\n",
    "    )\n",
    "\n",
    "\n",
    "base_model_dict = {alice: model_base_alice, bob: model_base_bob}\n",
    "\n",
    "sl_model = SLModel(\n",
    "    base_model_dict=base_model_dict,\n",
    "    device_y=device_y,\n",
    "    model_fuse=fuse_model,\n",
    "    dp_strategy_dict=None,\n",
    "    compressor=None,\n",
    "    simulation=True,\n",
    "    random_seed=1234,\n",
    "    backend='torch',\n",
    "    strategy='split_nn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182424d-1ac6-4674-94ba-e0d20a8d670f",
   "metadata": {},
   "source": [
    "## 定义 attacker_builder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec1463",
   "metadata": {},
   "source": [
    "### 2.Model Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c09e65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义decoder net\n",
    "class BankNetDecoder(nn.Module):  # cifar10 relu22 decoder网络 （目前结构就完全是和edge net的相反的层）\n",
    "    def __init__(self, latent_dim=64,target_dim=12):\n",
    "        super(BankNetDecoder, self).__init__()\n",
    "\n",
    "        self.delinear1 = nn.Linear(latent_dim, 128)\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        self.delinear2 = nn.Linear(128, 64)\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        self.delinear3 = nn.Linear(64, target_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        _in = x\n",
    "        for layer in self.children():\n",
    "            _in = layer(_in)\n",
    "        return _in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02030f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于攻击的数据：\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "def data_builder(data, label, batch_size):\n",
    "    def prepare_data():\n",
    "        # alice_data = data[:, :4]\n",
    "        # bob_data = data[:, 4:16]\n",
    "\n",
    "        numpy_alice = sf.reveal(data.partitions[alice].data).values\n",
    "        numpy_bob = sf.reveal(data.partitions[bob].data).values\n",
    "        alice_data = torch.tensor(numpy_alice, dtype=torch.float32)\n",
    "        bob_data = torch.tensor(numpy_bob, dtype=torch.float32)\n",
    "\n",
    "        # alice_dataset = TensorDataset(torch.tensor(alice_data))\n",
    "        # alice_dataloader = DataLoader(\n",
    "        #     dataset=alice_dataset,\n",
    "        #     shuffle=False,\n",
    "        #     batch_size=batch_size,\n",
    "        # )\n",
    "\n",
    "        bob_dataset = TensorDataset(torch.tensor(bob_data))\n",
    "        bob_dataloader = DataLoader(\n",
    "            dataset=bob_dataset,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        dataloader_dict = bob_dataloader\n",
    "        return dataloader_dict # 返回的是两个一样的，因为攻击者和被攻击者的数据是一样的emm\n",
    "\n",
    "    return prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274c2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack callbacks 创建\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/Products/secretflow/secretflow/ml/nn/sl/attacks/')\n",
    "\n",
    "from InverseModel import InverseModelAttackCallbacks\n",
    "\n",
    "\n",
    "# inverse model\n",
    "def create_attacker_builder(\n",
    "    trainloader=None,\n",
    "    testloader=None,\n",
    "):\n",
    "    def attacker_builder():\n",
    "        victim_model_dict = {\n",
    "            # 'bob': [SLBaseNet, model_save_path], # bob输入的是10啊？\n",
    "        }\n",
    "        optim_fn = optim_wrapper(optim.Adam, lr=0.0001)\n",
    "\n",
    "        decoder_model = TorchModel(\n",
    "            model_fn=BankNetDecoder,\n",
    "            loss_fn=None,\n",
    "            optim_fn=optim_fn,\n",
    "            metrics=None,\n",
    "        )\n",
    "\n",
    "\n",
    "        attacker = InverseModelAttackCallbacks(\n",
    "                data_type = 0, # 表格数据\n",
    "                inverse_dir = '/home/dengruijun/data/FinTech/Products/secretflow/drj-outs/InverseNetwork/inverted/',\n",
    "                decoder_route = '/home/dengruijun/data/FinTech/Products/secretflow/drj-outs/InverseNetwork/decoder_net.pth',\n",
    "                device = \"cuda:0\",\n",
    "                trainloader= trainloader,\n",
    "                testloader= testloader,\n",
    "\n",
    "                attack_party= alice,\n",
    "                victim_party= bob,\n",
    "                base_model_list=[alice,bob],\n",
    "                victim_model_dict=victim_model_dict,\n",
    "                decoder_model_wrapper=decoder_model,\n",
    "        )\n",
    "        return attacker\n",
    "\n",
    "    return attacker_builder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2deb30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(trainloader):  113\n",
      "len(testloader):  905\n",
      "trainloader:  <torch.utils.data.dataloader.DataLoader object at 0x7f9a8b99a800>\n",
      "trainloader in callbacks:  <torch.utils.data.dataloader.DataLoader object at 0x7f9a8b99a800>\n",
      "testloader in callbacks:  <torch.utils.data.dataloader.DataLoader object at 0x7f9a8b99a590>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_383139/122837605.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bob_dataset = TensorDataset(torch.tensor(bob_data))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "InvNet_path = '/home/dengruijun/data/FinTech/Products/secretflow/drj-outs/InverseNetwork/models/'\n",
    "if os.path.exists(InvNet_path):\n",
    "    shutil.rmtree(InvNet_path)\n",
    "os.mkdir(InvNet_path)\n",
    "model_save_path = InvNet_path + '/sl_model_victim'\n",
    "fuse_model_save_path = InvNet_path+'/sl_model_fuse'\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_bs = 32\n",
    "test_bs = 1\n",
    "trainloader = data_builder(train_fea, train_label, train_bs)()\n",
    "testloader = data_builder(test_fea, test_label, test_bs)()\n",
    "print(\"len(trainloader): \", len(trainloader))\n",
    "print(\"len(testloader): \", len(testloader))\n",
    "\n",
    "print(\"trainloader: \", trainloader)\n",
    "\n",
    "# for trn_x in testloader:\n",
    "#     print(trn_x[0].shape)\n",
    "\n",
    "callback_dict = [create_attacker_builder(\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    )()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1110d7-6f66-4b5b-8f3d-95088fcef5c4",
   "metadata": {},
   "source": [
    "## 开始训练和攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80f51bb-70d3-46c2-a5cc-f3fe45777b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:SL Train Params: {'self': <secretflow.ml.nn.sl.sl_model.SLModel object at 0x7f9a8d99af20>, 'x': VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7f9b3b15ab90>, PYURuntime(bob): <secretflow.data.core.partition.Partition object at 0x7f9b3b15b370>}, aligned=True), 'y': VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7f9b3b15bc70>}, aligned=True), 'batch_size': 64, 'epochs': 1, 'verbose': 1, 'callbacks': [<InverseModel.InverseModelAttackCallbacks object at 0x7f9a8b99ac50>], 'validation_data': (VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7f9b3b15b100>, PYURuntime(bob): <secretflow.data.core.partition.Partition object at 0x7f9b3b15b580>}, aligned=True), VDataFrame(partitions={PYURuntime(alice): <secretflow.data.core.partition.Partition object at 0x7f9b3b15be20>}, aligned=True)), 'shuffle': False, 'sample_weight': None, 'validation_freq': 1, 'dp_spent_step_freq': None, 'dataset_builder': None, 'audit_log_params': {}, 'early_stopping_batch_step': 0, 'early_stopping_warmup_step': 0, 'random_seed': 1234, 'audit_log_dir': None}\n",
      " 98%|█████████▊| 56/57 [00:00<00:00, 109.88it/s, {'train_loss': array(0.36142364, dtype=float32), 'train_BinaryAccuracy': array(0.8420907, dtype=float32), 'train_BinaryPrecision': array(0.08955224, dtype=float32), 'val_loss': array(0.17533527, dtype=float32), 'val_BinaryAccuracy': array(0.8729282, dtype=float32), 'val_BinaryPrecision': array(0., dtype=float32)}]\n",
      "INFO:root:Load decoder model from:/home/dengruijun/data/FinTech/Products/secretflow/drj-outs/InverseNetwork/decoder_net.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_net:  BankNetDecoder(\n",
      "  (delinear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (delinear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (ReLU2): ReLU()\n",
      "  (delinear3): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "----train decoder----\n",
      "client_net: \n",
      "GeneratedTorchModule(\n",
      "  (fc1): Linear(in_features=12, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      ")\n",
      "decoder_net: \n",
      "BankNetDecoder(\n",
      "  (delinear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (delinear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (ReLU2): ReLU()\n",
      "  (delinear3): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 905/905 [00:01<00:00, 904.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cos: 0.9883629339834603\n",
      "average euc: 0.17577367256194848\n",
      "average mse: 0.0040450720415895714\n",
      "average time: 0.0004304164022371914 avg infer time:0.00023147203645653488\n",
      "inverse done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [array(0.36142364, dtype=float32)],\n",
       " 'train_BinaryAccuracy': [array(0.8420907, dtype=float32)],\n",
       " 'train_BinaryPrecision': [array(0.08955224, dtype=float32)],\n",
       " 'val_loss': [array(0.17533527, dtype=float32)],\n",
       " 'val_BinaryAccuracy': [array(0.8729282, dtype=float32)],\n",
       " 'val_BinaryPrecision': [array(0., dtype=float32)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_model.fit(\n",
    "    train_fea,\n",
    "    train_label,\n",
    "    validation_data=(test_fea, test_label),\n",
    "    epochs=1,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    random_seed=1234,\n",
    "    dataset_builder=None,\n",
    "    callbacks=callback_dict, # 暂时注释掉，callback完成后恢复 @caibei\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cdaa4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的base model？\n",
    "sl_model.save_model(base_model_path=model_save_path,\n",
    "                    fuse_model_path=fuse_model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6352a-38da-4d13-9357-22d5835fa2a7",
   "metadata": {},
   "source": [
    "## 总结\n",
    "本文通过 UCI Sensorless Drive Diagnosis 数据集上的特征攻击任务来演示了如何通过隐语来使用 FeatureInferenceAttack。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b18f1-58b6-4d0f-be81-bc3da09e6a13",
   "metadata": {},
   "source": [
    "您可以：\n",
    "\n",
    "1. 下载并拆分数据集，准备训练、攻击使用的数据\n",
    "2. 定义拆分模型结构及 SL Model\n",
    "3. 定义 attacker_builder，在其中定义攻击需要的 data_builder 和 FeatureInfereceAttacker\n",
    "4. 调用 SL Model 进行训练攻击\n",
    "\n",
    "您可以在自己的数据集上进行尝试，如有任何问题，可以在 github 进行训练即可。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-sf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
